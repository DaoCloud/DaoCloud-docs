# 有效提升资源利用率，让闲置的算力跑起来

> 本文作者：云原生研究院产品经理 [Stella](https://github.com/Stella0621)

![提升资源利用率](https://docs.daocloud.io/daocloud-docs-images/docs/blogs/images/640.png)

## 资源利用率现状

据 Gartner 最新预测：“2023 年全球企业对云服务的⽀出预计将增⻓ 20.7%，达到 6000 亿美元，
⾼于 2022 年的 4900 亿美元以及 18.8% 的增⻓预测，并且 PaaS 增⻓率将达到 23.2%。
到 2025 年，超过 85% 的企业将采⽤优先上云的原则。”
与此同时，许多企业表示：“在没有云原⽣技术的情况下，将⽆法全⾯执⾏数字战略。”

对于已经拥抱云原⽣的企业来说，云技术为他们创造了丰厚的价值。
由于现代企业⼤多希望构建出具有⾼度可扩展性、弹性和灵活性的应⽤程序，
并能够快速更新迭代满⾜⾃身和客户需求，⽬前没有哪项技术能像云技术⼀样帮助企业实现这些⽬标。
尤其在提升资源利⽤率与节约成本⽅⾯，云原⽣已连续多年排名第⼀，成为了企业降本增效的最佳路径。

但随着许多企业规模持续扩⼤和业务量的不断增⻓，云基础设施服务成本⾼昂和资源利⽤率低下的问题也越来越突出，
并⾮所有计算资源都能得到充分利⽤，云上浪费性⽀出依然是令众多企业头疼的话题。
根据 Flexera《2022 年云状况》报告数据显示：
“优化云的现有使⽤率已连续六年成为受访企业的⾸要问题，云成本⽀出预计增加 29% ，其中估计 32% 的云⽀出会被浪费掉。”
另外，中国通信院在去年发表的关于云原⽣成本管理⽩⽪书中指出：“Kubernetes 资源预留过多，普遍存在 50% 以上的浪费。”
⽽刚过去的 2022 北美 KubeCon 会议中，“成本”也被提及多达 15 次。虽然云原生在提升企业资源利用率方面表现优异，
但是还有很大的进步空间。因此不论过去还是现在，如何进一步帮助企业有效提升资源利⽤率并充分发挥上云的价值，都是云原⽣从业者们义不容辞的责任。

## 如何进行资源优化

哪些资源在被浪费？

想要进⾏资源优化，必须先识别出哪些业务分配了过剩的资源。
⽽资源使⽤率通常通过 CPU、内存、磁盘、进出带宽等指标数据来衡量。
⼀般的公有云或私有云⼚商都会对这些指标的采集与查看提供现成的解决⽅案。

通过对历史指标的查看，可以快速了解资源的实际利⽤率以及周期性规律，在此基础上，才可进⾏细粒度的资源利⽤率优化。

### 1. 合理设置 Request 和 Limit

![Request 和 Limit](https://docs.daocloud.io/daocloud-docs-images/docs/blogs/images/usage01.png)

Kubernetes 中创建⼀个 Pod 时，可以指定容器对 CPU 和内存的资源请求量 (即 request)，以及资源限制量(即 limit)。
其中 Request 字段代表 Pod 对资源需求的最⼩值，每个 Kubernetes 节点可以分配给 Pod 的 CPU 和内存数量都是⼀定的。
调度器在调度时只会考虑那些未分配资源量且满⾜ Pod 请求量的节点。如果节点的未分配资源量⼩于 Pod 的资源请求量，
那么调度器则不会把 Pod 调度到此节点上。

在实践中，⼀个集群可能会有多个团队共同使⽤，各个团队为了应对流量的⾼峰时段，保证⾃⼰的⼯作负载的服务质量，
通常会为 Pod 申请较多的资源，也就是将 Request 设置得较⼤。这样 Request 和实际使⽤之间的差值就会被浪费，
⽽且这个差值的资源，是不能被其它⼯作负载所使⽤的。所以为了满⾜所有团队对资源的需求，集群中就需要加⼊更多的节点。
与此同时，更多的节点也带来了更多的资源浪费。

所以，合理地为容器设置 Request 和 Limit 值，对优化资源利⽤率⾄关重要，⽽设置 Pod 的 Request 和 Limit 也是⼀项艺术，
需要考虑应⽤的⼯作负载、集群的规模以及其他因素。为了合理地设置 Pod 的资源请求和限制，建议考虑以下⼏点：

1. 运⾏在 Pod 中的容器⼯作负载和资源需求。如果容器的⼯作负载很⾼，则需要更多的 CPU 和内存。

2. 为 Pod 设置的资源限制应该⾜够⼤，以便容器能够按需使⽤资源。如果设置的资源限制过⼩，则容器可能会被过早地杀死。

3. 为 Pod 设置的资源请求应该尽可能接近容器的实际资源需求，以帮助 Kubernetes 进⾏调度决策。
   如果资源 请求过⾼，则 Pod 可能⽆法调度到节点；如果过低，则可能会浪费节点上的资源。

为了确定 Pod 的资源请求和限制，可以使⽤ Kubernetes 的资源监控⼯具，例如 kubectl top 命令或者 Prometheus 和 Grafana。
这些⼯具可以帮助企业了解 Pod 和节点的资源使⽤情况，并根据实际需求调整资源请求和限制。

此外，还可以使⽤⾃动伸缩功能，根据 Pod 的资源使⽤情况动态调整副本数量，这样可以确保集群中的资源得以有效利⽤。

### 2. ⾃动扩缩容

Kubernetes 默认提供三种⾃动扩缩容的⽅式，分别是：

- Horizontal Pod Autoscaler (HPA)：横向⾃动扩缩容
- Vertical Pod Autoscaler (VPA)：垂直⾃动扩缩容
- Cluster Autoscaler (CA)：集群节点⾃动扩缩容

#### HPA

HPA 是⼀种⾃动伸缩功能，⽤于根据实际负载动态调整 Pod 的副本数量。
HPA 会定期监控 Deployment、ReplicationController、ReplicaSet 或者 StatefulSet 中 Pod 的资源使⽤情况，
根据设定的规则动态调整副本数量。例如，可以设定当 CPU 使⽤率超过 80% 时，HPA 就会增加副本数量；
当 CPU 使⽤率低于 50% 时，HPA 就 会减少副本数量。

通过 HPA，可以有效地提⾼ Deployment、ReplicationController、ReplicaSet 或者 StatefulSet 中 Pod 的资源利⽤率。

#### VPA

与 HPA 不同，VPA 意味着将更多资源 (例如：内存或 CPU) 分配给正在运⾏中的 Pod。
VPA 通过监控 Pod 的资源使⽤情况，并根据设定的⽬标使⽤率⾃动调整容器的资源请求和限制。
例如，如果 Pod 的 CPU 使⽤率较低，VPA 就会减少容器的 CPU 请求和限制；
如果 Pod 的 CPU 使⽤率较⾼，VPA 就会增加容器的 CPU 请求和限制。

使⽤ VPA 有如下优势:

- Pod 资源⽤其所需，提升集群节点使⽤效率
- 不必运⾏基准测试任务来确定 CPU 和内存请求的合适值
- VPA 可以随时调整 CPU 和内存请求，⽆需⼈为操作，因此可以减少维护时间。

需要注意的是：VPA ⽬前还没有⽣产就绪，在使⽤之前需要了解资源调节对应⽤的影响。

#### CA

CA 也是 Kubernetes 中的⼀种⾃动伸缩功能，可以根据集群的资源使⽤情况动态调整节点数量。
CA 通过监控集群 的资源使⽤情况，并根据设定的阈值⾃动调整节点数量。
例如，如果集群的 CPU 使⽤率超过了阈值，CA 就会增加 节点数量；
如果集群的 CPU 使⽤率低于阈值，CA 就会减少节点数量。
通过 CA 可以有效地提⾼ Kubernetes 集群的资源利⽤率。
当集群的资源使⽤情况发⽣变化时，CA 可以⾃动调整节点数量，使得集群能够更好地利⽤可⽤的资源。

#### ⼩结

通过使⽤弹性扩缩容，让业务能够通过⽇常请求的⾼低峰值，对服务器资源进⾏⾃动调整并⾼效利⽤资源，
这也是上云的本质能⼒。另外在容器中，弹性扩缩容⼀般分为容器层和 node 节点层，当业务负载的变化触发容器层的扩缩容，
容器的扩缩容会使节点集群的可分配资源量变化，并发⽣ node 节点的扩缩容。
业务上线不仅不需要提前申请过多的资源，⽽且申请下来的冗余资源也可以按需使⽤。

### 3. 错峰调度

Kubernetes 错峰调度是⼀种策略，可通过设置 Pod 的调度策略来实现，⽤于控制在同⼀时间内运⾏的作业数量。
⽬的是避免在系统负载过⾼的情况下运⾏⼤量作业，并允许在系统负载较低的时间运⾏更多的作业。
这种⽅法可以有效地利⽤计算资源，并在集群中的节点之间均衡负载。
可以使⽤ Kubernetes 的调度程序或第三⽅调度程序来实现错峰调度。错峰调度通常⽤于以下场景：

- 在系统负载较低的时间运⾏更多的作业，以提⾼资源利⽤率。
- 避免在系统负载过⾼的时间运⾏⼤量作业，以免造成系统瘫痪。
- 在集群中的节点之间均衡负载，以提⾼系统可靠性。

举个例⼦，假设你有⼀个每天运⾏⼀次的定期作业，该作业在早上 8 点开始运⾏。
如果你使⽤错峰调度策略，则可以调整作业的开始时间，使其在早上 6 点或 10 点开始运⾏，
⽽不是在早上 8 点。这样就可以避免在早上 8 点运⾏⼤量作业时造成的系统负载过⾼的问题，
在集群的资源使⽤较低的时段调度这些 Pod，从⽽减少集群的资源使⽤峰值。

### 4. 在线离线混部

在线离线业务混合部署是指在⼀个 Kubernetes 集群中同时运⾏离线业务和在线业务：

- 在线业务：需要实时处理的业务，例如⽹站、游戏、移动应⽤等。这类业务通常对延迟要求较低，但是对资源要求较⾼。
- 离线业务：不需要实时处理的业务，例如批处理作业、数据分析和备份等。这类业务通常消耗较多资源，但是可以允许较⻓的延迟。

例如，某公司可能有⼀个⽹站，⽤来提供⽹上购物和物流服务。该服务对稳定性的要求较⾼，
因为在线⽹站的流畅性关乎⽤户的使⽤体验。为了确保⽹站的可⽤性和响应速度，
在部署时这类服务的 QoS 等级较⾼，在分配资源时享有更⾼优先级。
同时⽹站的资源使⽤率与⽹站流量成正⽐，⽩天⾼峰，夜⾥低峰，有明显的流量潮汐特性。

同时该公司可能需要定期备份其客户数据库，并对过去⼀年的销售数据进⾏分析，以确定接下来的营销策略。
为了实现这个⽬标，公司可以使⽤ Kubernetes 集群来运⾏两个离线业务⼯作作业：
⼀个⽤于数据备份，⼀个⽤于数据分析。数据备份⼯作作业可以每天凌晨运⾏⼀次，
将客户数据库的数据备份到云存储中。数据分析⼯作作业可以每周末运⾏⼀次，对过去⼀年的销售数据进⾏分析，并⽣成报告。

由此可⻅在线服务的流量存在周期性，对延时敏感，资源使⽤率低，对稳定性、服务资源与负载有着很⾼的要求；
⽽离线作业通常可以容忍较⾼的时延，并且失败任务可重启。这两种类型的服务负载在分时间段使⽤、资源互补上存在极⼤的优化空间。
例如，可以为离线业务设置较低的资源请求和限制，并使⽤较低优先级的调度策略。
这样，当在线业务需要资源时，离线业务就会⾃动让出资源。通过在离线业务混合部署，
可以有效地利⽤集群中的资源，并同时保证在线业务的可⽤性和响应速度。

## 总结

Kubernetes 可以使⽤多种⽅式来提升资源利⽤率。通过设置 Pod 的资源请求和限制、使⽤⾃动伸缩功能、错峰调度策略以及混部技术，
皆可有效地优化 Kubernetes 集群的计算资源，更好地满⾜业务需求并节省成本。
当然，在实际应⽤中，我们还可以根据具体的业务场景进⾏更多的优化。
总的来说，要提升 Kubernetes 的资源利⽤率，只要对应⽤程序的运⾏⽅式和资源使⽤情况进⾏全⾯分析，
并使⽤适当的⼯具和⽅法来提升资源利⽤率，就能够让 Kubernetes 集群更加⾼效地运⾏。

[下载 DCE 5.0](../download/dce5.md){ .md-button .md-button--primary }
[安装 DCE 5.0](../install/intro.md){ .md-button .md-button--primary }
[申请社区免费体验](../dce/license0.md){ .md-button .md-button--primary }
