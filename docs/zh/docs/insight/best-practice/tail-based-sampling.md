# å°¾éƒ¨é‡‡æ ·æ–¹æ¡ˆ

å°¾éƒ¨é‡‡æ ·å¤„ç†å™¨æ ¹æ®ä¸€ç»„å®šä¹‰çš„ç­–ç•¥å¯¹é“¾è·¯è¿›è¡Œé‡‡æ ·ã€‚ä½†æ˜¯ï¼Œé“¾è·¯çš„æ‰€æœ‰è·¨åº¦ï¼ˆspanï¼‰å¿…é¡»ç”±åŒä¸€æ”¶é›†å™¨å®ä¾‹æ¥æ”¶ï¼Œä»¥åšå‡ºæœ‰æ•ˆçš„é‡‡æ ·å†³ç­–ã€‚

å› æ­¤ï¼Œéœ€è¦å¯¹ Insight çš„ Global Opentelemetry Collector  æ¶æ„è¿›è¡Œè°ƒæ•´ä»¥å®ç°å°¾éƒ¨é‡‡æ ·ç­–ç•¥ã€‚

## å…·ä½“æ”¹åŠ¨

åœ¨ Global Opentelemetry Collector å‰é¢å¼•å…¥å…·æœ‰  Load Balancer åŠŸèƒ½çš„ Otel Colã€‚


## æ”¹åŠ¨æ­¥éª¤

### éƒ¨ç½²å…·æœ‰ Load Balance èƒ½åŠ›çš„ OTEL COL ç»„ä»¶

??? note "ç‚¹å‡»æŸ¥çœ‹éƒ¨ç½²é…ç½®"

    ```yaml
    kind: ClusterRole
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: insight-otel-collector-lb
    rules:
    - apiGroups: [""]
      resources: ["endpoints"]
      verbs: ["get", "watch", "list"]
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: insight-otel-collector-lb
      namespace: insight-system
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: insight-otel-collector-lb
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: insight-otel-collector-lb
    subjects:
    - kind: ServiceAccount
      name: insight-otel-collector-lb
      namespace: insight-system
    ---
    kind: ConfigMap
    metadata:
      labels:
        app.kubernetes.io/component: opentelemetry-collector
        app.kubernetes.io/instance: insight-otel-collector-lb
        app.kubernetes.io/name: insight-otel-collector-lb
      name: insight-otel-collector-lb-collector
      namespace: insight-system
    apiVersion: v1
    data:
      collector.yaml: |
        receivers:
          otlp:
            protocols:
              grpc:
              http:
          jaeger:
            protocols:
              grpc:
        processors:
    
        extensions:
          health_check:
          pprof:
            endpoint: :1888
          zpages:
            endpoint: :55679
        exporters:
          logging:
          loadbalancing:
            routing_key: "traceID"
            protocol:
              otlp:
                # all options from the OTLP exporter are supported
                # except the endpoint
                timeout: 1s
                tls:
                  insecure: true
            resolver:
              k8s:
                service: insight-opentelemetry-collector
                ports:
                  - 4317
        service:
          extensions: [pprof, zpages, health_check]
          pipelines:
            traces:
              receivers: [otlp, jaeger]
              exporters: [loadbalancing]
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app.kubernetes.io/component: opentelemetry-collector
        app.kubernetes.io/instance: insight-otel-collector-lb
        app.kubernetes.io/name: insight-otel-collector-lb
      name: insight-otel-collector-lb
      namespace: insight-system
    spec:
      replicas: 2
      selector:
        matchLabels:
          app.kubernetes.io/component: opentelemetry-collector
          app.kubernetes.io/instance: insight-otel-collector-lb
          app.kubernetes.io/name: insight-otel-collector-lb
      template:
        metadata:
          labels:
            app.kubernetes.io/component: opentelemetry-collector
            app.kubernetes.io/instance: insight-otel-collector-lb
            app.kubernetes.io/name: insight-otel-collector-lb
        spec:
          containers:
          - args:
            - --config=/conf/collector.yaml
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            image: ghcr.m.daocloud.io/openinsight-proj/opentelemetry-collector-contrib:5baef686672cfe5551e03b5c19d3072c432b6f33
            imagePullPolicy: IfNotPresent
            livenessProbe:
              failureThreshold: 3
              httpGet:
                path: /
                port: 13133
                scheme: HTTP
              periodSeconds: 10
              successThreshold: 1
              timeoutSeconds: 1
            name: otc-container
            resources:
              limits:
                cpu: '1'
                memory: 2Gi
              requests:
                cpu: 100m
                memory: 400Mi
            ports:
            - containerPort: 14250
              name: jaeger-grpc
              protocol: TCP
            - containerPort: 8888
              name: metrics
              protocol: TCP
            - containerPort: 4317
              name: otlp-grpc
              protocol: TCP
            - containerPort: 4318
              name: otlp-http
              protocol: TCP
            - containerPort: 55679
              name: zpages
              protocol: TCP
    
            volumeMounts:
            - mountPath: /conf
              name: otc-internal
    
          serviceAccount: insight-otel-collector-lb
          serviceAccountName: insight-otel-collector-lb
          volumes:
          - configMap:
              defaultMode: 420
              items:
              - key: collector.yaml
                path: collector.yaml
              name: insight-otel-collector-lb-collector
            name: otc-internal
    ---
    kind: Service
    apiVersion: v1
    metadata:
      name: insight-opentelemetry-collector-lb
      namespace: insight-system
      labels:
        app.kubernetes.io/component: opentelemetry-collector
        app.kubernetes.io/instance: insight-otel-collector-lb
        app.kubernetes.io/name: insight-otel-collector-lb
    spec:
      ports:
        - name: fluentforward
          protocol: TCP
          port: 8006
          targetPort: 8006
        - name: jaeger-compact
          protocol: UDP
          port: 6831
          targetPort: 6831
        - name: jaeger-grpc
          protocol: TCP
          port: 14250
          targetPort: 14250
        - name: jaeger-thrift
          protocol: TCP
          port: 14268
          targetPort: 14268
        - name: metrics
          protocol: TCP
          port: 8888
          targetPort: 8888
        - name: otlp
          protocol: TCP
          appProtocol: grpc
          port: 4317
          targetPort: 4317
        - name: otlp-http
          protocol: TCP
          port: 4318
          targetPort: 4318
        - name: zipkin
          protocol: TCP
          port: 9411
          targetPort: 9411
        - name: zpages
          protocol: TCP
          port: 55679
          targetPort: 55679
      selector:
        app.kubernetes.io/component: opentelemetry-collector
        app.kubernetes.io/instance: insight-otel-collector-lb
        app.kubernetes.io/name: insight-otel-collector-lb
    ```

### é…ç½®å°¾éƒ¨é‡‡æ ·è§„åˆ™

!!! note

    éœ€è¦åœ¨åŸæœ¬ insight-otel-collector-config configmap é…ç½®ç»„ä¸­å¢åŠ å°¾éƒ¨é‡‡æ ·ï¼ˆtail_sampling processorsï¼‰çš„è§„åˆ™ã€‚

1. åœ¨ `processor` ä¸­å¢åŠ å¦‚ä¸‹å†…å®¹ï¼Œå…·ä½“è§„åˆ™å¯è°ƒæ•´ï¼›å‚è€ƒï¼š[å®˜æ–¹ç¤ºä¾‹](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/tailsamplingprocessor/README.md#a-practical-example)

    ```yaml
    ........
    tail_sampling:
      decision_wait: 10s # ç­‰å¾… 10 ç§’ï¼Œè¶…è¿‡ 10 ç§’åçš„ traceid å°†ä¸å†å¤„ç†
      num_traces: 1500000  # å†…å­˜ä¸­ä¿å­˜çš„ trace æ•°ï¼Œå‡è®¾æ¯ç§’ 1000 æ¡ traceï¼Œæœ€å°ä¸ä½äº 1000 * decision_wait * 2ï¼›è®¾ç½®è¿‡å¤§ä¼šå ç”¨è¿‡å¤šçš„å†…å­˜èµ„æºï¼Œè¿‡å°ä¼šå¯¼è‡´éƒ¨åˆ† trace è¢« drop æ‰
      expected_new_traces_per_sec: 10
      policies: # ä¸ŠæŠ¥ç­–ç•¥
        [
            {
              name: latency-policy,
              type: latency,  # è€—æ—¶è¶…è¿‡ 500ms ä¸ŠæŠ¥
              latency: {threshold_ms: 500}
            },
            {
              name: status_code-policy,
              type: status_code,  # çŠ¶æ€ç ä¸º ERROR çš„ä¸ŠæŠ¥
              status_code: {status_codes: [ ERROR ]}
            }
        ]
    ......
    # ç»„åˆé‡‡æ ·
    tail_sampling:
      decision_wait: 10s # ç­‰å¾… 10 ç§’ï¼Œè¶…è¿‡ 10 ç§’åçš„ traceid å°†ä¸å†å¤„ç†
      num_traces: 1500000  # å†…å­˜ä¸­ä¿å­˜çš„ trace æ•°ï¼Œå‡è®¾æ¯ç§’ 1000 æ¡ traceï¼Œæœ€å°ä¸ä½äº 1000 * decision_wait * 2ï¼›è®¾ç½®è¿‡å¤§ä¼šå ç”¨è¿‡å¤šçš„å†…å­˜èµ„æºï¼Œè¿‡å°ä¼šå¯¼è‡´éƒ¨åˆ† trace è¢« drop æ‰
      expected_new_traces_per_sec: 10
      policies: [
          {
            name: debug-worker-cluster-sample-policy,
            type: and,
            and:
              {
                and_sub_policy:
                  [
                    {
                      name: service-name-policy,
                      type: string_attribute,
                      string_attribute:
                        { key: k8s.cluster.id, values: [xxxxxxx] },
                    },
                    {
                      name: trace-status-policy,
                      type: status_code,
                      status_code: { status_codes: [ERROR] },
                    },
                    {
                      name: probabilistic-policy,
                      type: probabilistic,
                      probabilistic: { sampling_percentage: 1 },
                    }
                  ]
              }
          }
        ]
    ```

2. åœ¨ otel col pipeline ä¸­æ¿€æ´»è¯¥ `processor` ï¼š

    ```yaml
    traces:
      exporters:
        - servicegraph
        - otlp/jaeger
      processors:
        - memory_limiter
        - tail_sampling # ğŸ‘ˆ
        - batch
      receivers:
        - otlp
    ```

3. é‡å¯ `insight-opentelemetry-collector` ç»„ä»¶ã€‚

4. åœ¨éƒ¨ç½² Insight-agent æ—¶ï¼Œå°†é“¾è·¯æ•°æ®çš„ä¸ŠæŠ¥åœ°å€ä¿®æ”¹ä¸º `otel-col` LB çš„ `4317` ç«¯å£åœ°å€ã€‚

    ```yaml
    ....
        exporters:
          otlp/global:
            endpoint: insight-opentelemetry-collector-lb.insight-system.svc.cluster.local:4317  # ğŸ‘ˆ ä¿®æ”¹ä¸º lb åœ°å€
    ```
